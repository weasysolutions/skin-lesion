{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## *Lesiones de la piel*\n",
    "\n",
    "\n",
    "### [Aprendizaje profundo: Redes Neuronales Convolutivas con TensorFlow](https://www.kaggle.com/vbookshelf/skin-lesion-analyzer-tensorflow-js-web-app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivación\n",
    "\n",
    "La dermatoscopia es una técnica de diagnóstico ampliamente utilizada que mejora el diagnóstico de lesiones cutáneas benignas y malignas en comparación con el examen a simple vista. Las imágenes dermatoscópicas también son una fuente adecuada para entrenar redes neuronales artificiales para diagnosticar automáticamente lesiones cutáneas pigmentadas. \n",
    "\n",
    "Los avances recientes en las capacidades de las tarjetas gráficas y las técnicas de aprendizaje en máquinas establecen nuevos puntos de referencia con respecto a la complejidad de las redes neuronales y aumentan las expectativas de que pronto estarán disponibles sistemas de diagnóstico automatizados que diagnostican todo tipo de lesiones cutáneas pigmentadas sin la necesidad de experiencia humana (https://arxiv.org/abs/1803.10417).\n",
    "\n",
    "La capacitación de algoritmos de diagnóstico basados ​​en redes neuronales requiere un gran número de imágenes anotadas (o etiquetadas), pero el número de imágenes dermatoscópicas de alta calidad con diagnósticos confiables está limitado o restringido a solo unas pocas clases de enfermedades.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### El archivo ISIC (International Skin Imaging Collaboration)\n",
    "\n",
    "El archivo ISIC (https://isic-archive.com/) es una colección de múltiples bases de datos e incluye actualmente 13786 imágenes dermatoscópicas (a partír del 12 de febrero de 2018). Es la fuente estándar para la investigación de análisis de imágenes dermatoscópicas. Sin embargo, está sesgada hacia las lesiones melanocíticas (12893 de 13786 imágenes son nevi ormelanomas). \n",
    "\n",
    "Para impulsar la investigación sobre el diagnóstico automatizado de imágenes dermatoscópicas, recientemente investigadores de la Univ. Médica de Vienna y la Universidad de Queensland lanzaron el conjunto de datos HAM10000 [“Human Against Machine con 10000 imágenes de entrenamiento”]. Han colgado el conjunto de datos a través del archivo ISIC.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "*El artículo original se encuentra en la siguiente liga: <br>*\n",
    "> [El conjunto de datos HAM10000: una gran colección de imágenes dermatoscópicas de múltiples fuentes de lesiones cutáneas pigmentadas comunes](https://arxiv.org/abs/1803.10417)<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d6f77793e7ebbcd523899bafaa9dae9763b9a0a5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Introduction y Objetivo de la Lección **\n",
    "\n",
    "Este libro detalla un proceso que construye el modelo y luego convertirlo de Keras a Tensorflow.js. El código javascript, html y css para la aplicación está disponible en github. <br>\n",
    "\n",
    "Si un modelo tiene una precisión del 60%, por lo general se consideraría un modelo malo. Sin embargo, si también tiene una precisión del 3% superior al 90% y el objetivo requiere que produzca 3 predicciones, entonces puede ser un buen modelo.\n",
    "\n",
    "*Este es el objetivo que se ha definido para esta tarea:*\n",
    "\n",
    "> Crear una herramienta en línea que pueda decirle a los médicos y tecnólogos de laboratorio los tres diagnósticos de mayor probabilidad para una lesión cutánea determinada. Esto les ayudará a identificar rápidamente a los pacientes de alta prioridad y acelerar su flujo de trabajo. La aplicación debe producir un resultado en menos de 3 segundos. Para garantizar la privacidad, las imágenes se deben preprocesar y analizar localmente y nunca se deben cargar en un servidor externo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [ Descripción de las categorías del diagnóstico:](https://arxiv.org/abs/1803.10417) <br>\n",
    "\n",
    " **nv** <br>\n",
    " Los nevos melanocíticos son neoplasias benignas de melanocitos y aparecen en una gran variedad de variantes, que están incluidas en nuestra serie. Las variantes pueden diferir significativamente desde un punto de vista dermatoscópico. <br>\n",
    " *[6705 imágenes]*\n",
    " ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    " \n",
    " **mel** <br>\n",
    " El melanoma es una neoplasia maligna derivada de melanocitos que puede aparecer en diferentes variantes. Si se extirpa en una etapa temprana, se puede curar por escisión quirúrgica simple. Los melanomas pueden ser invasivos o no invasivos (in situ). Se incluyen todas las variantes de melanoma, incluido el melanoma in situ, pero se excluye el melanoma no pigmentado, subungueal, ocular o mucoso. <br> \n",
    " *[1113 imágenes]*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [ Descripción de las categorías del diagnóstico:](https://arxiv.org/abs/1803.10417) <br>\n",
    " \n",
    "** bkl ** <br>\n",
    " La \"queratosis benigna\" es una clase genérica que incluye queratosis seborreica (\"verruga senil\"), lentigo solar, que puede considerarse una variante plana de la queratosis seborreica y liquenoplus como queratosis (LPLK), que corresponde a una seborréica Queratosis o un lentigo solar con inflamación y regresión [22]. Los tres subgrupos pueden tener un aspecto dermatoscópico diferente, pero los agrupamos porque son biológicamente similares y, a menudo, se informan bajo el mismo término genérico histopatológicamente. Desde un punto de vista dermatoscópico, las queratosis de tipo liquen plano son especialmente desafiantes porque pueden mostrar características morfológicas que simulan un melanoma [23] y con frecuencia se realizan biopsias o se extirpan por razones diagnósticas.\n",
    "*[1099 imágenes]*\n",
    "***\n",
    "**bcc** <br>\n",
    "El carcinoma de células basales es una variante común del cáncer de piel epitelial que rara vez hace metástasis pero crece destructivamente si no se trata. Aparece en diferentes variantes morfológicas (plana, nodular, pigmentada, quística, etc.), todas incluidas en este conjunto. <br>\n",
    "*[514 imágenes] *\n",
    "*** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "d3f6843b78793e1c047ca6909a7449dc9bfc3f1c",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "** akiec ** <br>\n",
    "Las queratosis actínicas (queratosis solares) y el carcinoma intraepitelial (enfermedad de Bowen) son variantes no invasivas comunes del carcinoma de células escamosas que pueden tratarse localmente sin cirugía. Algunos autores los consideran como precursores de carcinomas de células escamosas y no como carcinomas reales. Sin embargo, hay acuerdo en que estas lesiones pueden progresar a un carcinoma de células escamosas invasivo, que generalmente no está pigmentado. Ambas neoplasias comúnmente muestran escamas en la superficie y comúnmente están desprovistas de pigmento. Las queratosis actínicas son más comunes en la cara y la enfermedad de Bowen es más común en otros sitios del cuerpo. Debido a que ambos tipos están inducidos por la luz ultravioleta, la piel circundante generalmente se caracteriza por daños severos causados ​​por el sol, excepto en los casos de enfermedad de Bowen que son causados por la infección del virus del papiloma humano y no por los rayos UV. Existen variantes pigmentadas para la enfermedad de Bowen [19] y para las queratosis actínicas [20]. Ambos están incluidos en este conjunto. <br>\n",
    "*[327 imágenes]*\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "** vasc ** <br>\n",
    "Las lesiones vasculares de la piel en el conjunto de datos van desde los angiomas de cereza hasta los angioqueratomas [25] y los granulomas piógenos [26]. La hemorragia también se incluye en esta categoría. <br>\n",
    "*[142 imágenes]*\n",
    "\n",
    "** df ** <br>\n",
    "El dermatofibroma es una lesión benigna de la piel considerada como una proliferación benigna o una reacción inflamatoria a un trauma mínimo. Es marrón y con frecuencia muestra una zona central de fibrosis dermatoscópica [24]. <br>\n",
    "*[115 imágenes]*\n",
    "\n",
    "\n",
    "<br> * [Imágenes totales = 10015] *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### [TensorFlow](https://www.tensorflow.org/)\n",
    "\n",
    "TensorFlow es una plataforma de código abierto  para el aprendizaje automático. Cuenta con un ecosistema integral y flexible de herramientas, bibliotecas y recursos de la comunidad que permite a los investigadores impulsar el estado de la técnica en ML y los desarrolladores pueden crear y desplegar fácilmente aplicaciones potenciadas por ML.\n",
    "\n",
    "### [Keras](https://keras.io/)\n",
    "\n",
    "Keras es una interfaz de programación de aplicaciones (API) de redes neuronales de alto nivel, escrita en Python y capaz de ejecutarse sobre TensorFlow, CNTK o Theano. Fue desarrollado con un enfoque en permitir la experimentación rápida. Poder pasar de la idea al resultado con el menor retraso posible es clave para hacer una buena investigación.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Importamos todas las bibliotecas que utilizaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#Generamos las semillas aleatorias iniciales\n",
    "from numpy.random import seed\n",
    "seed(101)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(101)\n",
    "\n",
    "# numpy para el manejo de arreglos\n",
    "\n",
    "# numpy y pandas para el manejo de los datos\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "371731306c3e504b191979706e826c247def88dc",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# tensorflow para el aprendizaje automatico\n",
    "#  Keras backend para las redes neuronales\n",
    "import tensorflow\n",
    "\n",
    "# Las capas seran densas \n",
    "# El optimizador Dropout\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "371731306c3e504b191979706e826c247def88dc"
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(101)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(101)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import keras\n",
    "#from keras import backend as K\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Redes Neuronales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "371731306c3e504b191979706e826c247def88dc"
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "#Semilla para el generador de números aleatorios de numpy\n",
    "seed(101)\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "#Semilla para el generador de números aleatorios de tensorflow\n",
    "set_random_seed(101)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import keras\n",
    "#from keras import backend as K\n",
    "\n",
    "import tensorflow\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "import os\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d5a0a200bfc57c5489eaa930255d9420a7d01c47"
   },
   "outputs": [],
   "source": [
    "os.listdir('../input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "086162161ba405b800863e7d545b5917e5205984"
   },
   "source": [
    "### Create the directory structure\n",
    "\n",
    "In these folders we will store the images that will later be fed to the Keras generators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d24ef21f9f2359b8bf6b3e7a0b8ab5a43daaf566"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a new directory\n",
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "#[CREATE FOLDERS INSIDE THE BASE DIRECTORY]\n",
    "\n",
    "# now we create 7 folders inside 'base_dir':\n",
    "\n",
    "# train_dir\n",
    "    # nv\n",
    "    # mel\n",
    "    # bkl\n",
    "    # bcc\n",
    "    # akiec\n",
    "    # vasc\n",
    "    # df\n",
    " \n",
    "# val_dir\n",
    "    # nv\n",
    "    # mel\n",
    "    # bkl\n",
    "    # bcc\n",
    "    # akiec\n",
    "    # vasc\n",
    "    # df\n",
    "\n",
    "# create a path to 'base_dir' to which we will join the names of the new folders\n",
    "# train_dir\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "# val_dir\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "# [CREATE FOLDERS INSIDE THE TRAIN, VALIDATION AND TEST FOLDERS]\n",
    "# Inside each folder we create seperate folders for each class\n",
    "\n",
    "# create new folders inside train_dir\n",
    "nv = os.path.join(train_dir, 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join(train_dir, 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join(train_dir, 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join(train_dir, 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join(train_dir, 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join(train_dir, 'vasc')\n",
    "os.mkdir(vasc)\n",
    "df = os.path.join(train_dir, 'df')\n",
    "os.mkdir(df)\n",
    "\n",
    "\n",
    "\n",
    "# create new folders inside val_dir\n",
    "nv = os.path.join(val_dir, 'nv')\n",
    "os.mkdir(nv)\n",
    "mel = os.path.join(val_dir, 'mel')\n",
    "os.mkdir(mel)\n",
    "bkl = os.path.join(val_dir, 'bkl')\n",
    "os.mkdir(bkl)\n",
    "bcc = os.path.join(val_dir, 'bcc')\n",
    "os.mkdir(bcc)\n",
    "akiec = os.path.join(val_dir, 'akiec')\n",
    "os.mkdir(akiec)\n",
    "vasc = os.path.join(val_dir, 'vasc')\n",
    "os.mkdir(vasc)\n",
    "df = os.path.join(val_dir, 'df')\n",
    "os.mkdir(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4ae8d37fdee293aaffa71a79019dd7277f8288fc"
   },
   "source": [
    "### Create Train and Val Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "268503398ef61904e05a2c0b0667d589f08a19a8"
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('../input/HAM10000_metadata.csv')\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c46ea5967e095d31dcf144b6f57f0343878fa432"
   },
   "source": [
    "### Create a stratified val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53e4b7b152ed831a7d7516156ac300c0e6985ffc"
   },
   "outputs": [],
   "source": [
    "# this will tell us how many images are associated with each lesion_id\n",
    "df = df_data.groupby('lesion_id').count()\n",
    "\n",
    "# now we filter out lesion_id's that have only one image associated with it\n",
    "df = df[df['image_id'] == 1]\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "24720fe3ea9f2f4b571abd09ecfbb931d6429852"
   },
   "outputs": [],
   "source": [
    "# here we identify lesion_id's that have duplicate images and those that have only\n",
    "# one image.\n",
    "\n",
    "def identify_duplicates(x):\n",
    "    \n",
    "    unique_list = list(df['lesion_id'])\n",
    "    \n",
    "    if x in unique_list:\n",
    "        return 'no_duplicates'\n",
    "    else:\n",
    "        return 'has_duplicates'\n",
    "    \n",
    "# create a new colum that is a copy of the lesion_id column\n",
    "df_data['duplicates'] = df_data['lesion_id']\n",
    "# apply the function to this new column\n",
    "df_data['duplicates'] = df_data['duplicates'].apply(identify_duplicates)\n",
    "\n",
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "08b7eef3e0ac4112f63b8fb26ce19d55483cbc04"
   },
   "outputs": [],
   "source": [
    "df_data['duplicates'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "995445dfda2745165a53e61f42615104b951d4af"
   },
   "outputs": [],
   "source": [
    "# now we filter out images that don't have duplicates\n",
    "df = df_data[df_data['duplicates'] == 'no_duplicates']\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "39fde25b59a9452cf700c5b2ff82cc7cc45c4a33"
   },
   "outputs": [],
   "source": [
    "# now we create a val set using df because we are sure that none of these images\n",
    "# have augmented duplicates in the train set\n",
    "y = df['dx']\n",
    "\n",
    "_, df_val = train_test_split(df, test_size=0.17, random_state=101, stratify=y)\n",
    "\n",
    "df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1df37227f7ce993d054ed5b8480ee724696fc210"
   },
   "outputs": [],
   "source": [
    "df_val['dx'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "08c5e12fcef2da5f49267a6b82161b2c52c2b20a"
   },
   "source": [
    "### Create a train set that excludes images that are in the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03715a6cf5aeb6430ee144a84eb10dde216c0fb9"
   },
   "outputs": [],
   "source": [
    "# This set will be df_data excluding all rows that are in the val set\n",
    "\n",
    "# This function identifies if an image is part of the train\n",
    "# or val set.\n",
    "def identify_val_rows(x):\n",
    "    # create a list of all the lesion_id's in the val set\n",
    "    val_list = list(df_val['image_id'])\n",
    "    \n",
    "    if str(x) in val_list:\n",
    "        return 'val'\n",
    "    else:\n",
    "        return 'train'\n",
    "\n",
    "# identify train and val rows\n",
    "\n",
    "# create a new colum that is a copy of the image_id column\n",
    "df_data['train_or_val'] = df_data['image_id']\n",
    "# apply the function to this new column\n",
    "df_data['train_or_val'] = df_data['train_or_val'].apply(identify_val_rows)\n",
    "   \n",
    "# filter out train rows\n",
    "df_train = df_data[df_data['train_or_val'] == 'train']\n",
    "\n",
    "\n",
    "print(len(df_train))\n",
    "print(len(df_val))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
